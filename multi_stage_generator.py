# multi_stage_generator.py
import os
import json
import re
import time
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from pathlib import Path
from utils import ConfigManager  # å¯¼å…¥ConfigManager

@dataclass
class GenerationStage:
    """ç”Ÿæˆé˜¶æ®µå®šä¹‰"""
    name: str
    description: str
    max_tokens: int = 2048
    temperature: float = 0.2
    depends_on: List[str] = field(default_factory=list)
    output_patterns: List[str] = field(default_factory=list)

class AFSimProjectStructure:
    """AFSIMé¡¹ç›®ç»“æ„åˆ†æå™¨"""
    
    def __init__(self):
        # è·å–é…ç½®ç®¡ç†å™¨
        self.config = ConfigManager()
        # åŸºç¡€æ–‡ä»¶
        self.base_files = [
            "main.txt",
            "README.md",
            "project_structure.json"
        ]
    
    def analyze_requirements(self, query: str) -> Dict:
        """åˆ†æéœ€æ±‚ï¼Œç¡®å®šé¡¹ç›®ç»“æ„"""
        query_lower = query.lower()
                
        # æ£€æµ‹éœ€è¦çš„ç»„ä»¶
        components = self._detect_components(query_lower)
        
        # æ„å»ºé¡¹ç›®ç»“æ„
        structure = self._build_project_structure(components)
        
        return {
            "components": components,
            "structure": structure,
            "stages": self._generate_stages(components)
        }
    
    def _detect_components(self, query: str) -> Dict[str, bool]:
        """æ£€æµ‹éœ€è¦çš„ç»„ä»¶"""
        return {
            "platforms": any(word in query for word in [
                "å¹³å°", "å¯¼å¼¹", "ç‚¸å¼¹", "è½¦", "å«æ˜Ÿ", "èˆ¹", "å¦å…‹", "é£è¡Œå™¨", "é£æœº", "å‘å°„è½¦"
            ]),
            "scenarios": any(word in query for word in [
                "çº¢", "è“", "é˜Ÿ", "å¯¹æŠ—"
            ]),
            "processors": any(word in query for word in [
                "å¤„ç†å™¨", "æ§åˆ¶", "åˆ¶å¯¼", "è·Ÿè¸ª"
            ]),
            "weapons": any(word in query for word in [
                "æ­¦å™¨å¹³å°", "æ­¦å™¨", "å¯¼å¼¹", "æ‹¦æˆªå¼¹","ç«ç®­", "ç‚¸å¼¹", "ç«ç‚®"
            ]),
            "sensors": any(word in query for word in [
                "ä¼ æ„Ÿå™¨", "é›·è¾¾", "æ¢æµ‹", "è·Ÿè¸ª", "çº¢å¤–", "å…‰å­¦"
            ]),
            "signatures": any(word in query for word in [
                "ç‰¹å¾", "é›·è¾¾åå°„", "çº¢å¤–ç‰¹å¾", "å…‰å­¦ç‰¹å¾", "é›·è¾¾æˆªé¢ç§¯", "éšèº«"
            ]),
        }
    
    def _build_project_structure(self, components: Dict) -> Dict:
        """æ„å»ºé¡¹ç›®ç»“æ„"""
        structure = {
            "files": self.base_files.copy(),
            "folders": []
        }
        
        # æ ¹æ®æ£€æµ‹åˆ°çš„ç»„ä»¶æ·»åŠ ç›¸åº”çš„æ–‡ä»¶å¤¹
        folder_mapping = {
            "platforms": "platforms",
            "scenarios": "scenarios",
            "processors": "processors",
            "weapons": "weapons",
            "sensors": "sensors",
            "signatures": "signatures",
        }

        # æ·»åŠ æ£€æµ‹åˆ°çš„ç»„ä»¶çš„æ–‡ä»¶å¤¹
        for component, has_component in components.items():
            if has_component and component in folder_mapping:
                folder_name = folder_mapping[component]
                if folder_name not in structure["folders"]:
                    structure["folders"].append(folder_name)
        
        # ç¡®ä¿è‡³å°‘æœ‰å¹³å°å’Œåœºæ™¯æ–‡ä»¶å¤¹ï¼ˆå¤§éƒ¨åˆ†é¡¹ç›®éƒ½éœ€è¦ï¼‰
        if "platforms" not in structure["folders"] and components["platforms"]:
            structure["folders"].append("platforms")
        if "scenarios" not in structure["folders"] and components["scenarios"]:
            structure["folders"].append("scenarios")
        
        # æ’åºæ–‡ä»¶å¤¹ï¼Œè®©å¸¸ç”¨æ–‡ä»¶å¤¹åœ¨å‰é¢
        preferred_order = ["platforms", "scenarios", "weapons", "sensors", "processors"]
        structure["folders"] = sorted(
            structure["folders"],
            key=lambda x: (preferred_order.index(x) if x in preferred_order else len(preferred_order), x)
        )
        
        return structure
    
    def _generate_stages(self, components: Dict) -> List[Dict]:
        """ç”Ÿæˆé˜¶æ®µè®¡åˆ’ï¼Œä»config.yamlè¯»å–å‚æ•°"""
        # ä»é…ç½®è·å–é˜¶æ®µå®šä¹‰
        config_stages = self.config.get('generation.stages', [])
        
        # åˆ›å»ºé˜¶æ®µåˆ—è¡¨
        stages = []
        
        # é¦–å…ˆæ·»åŠ é¡¹ç›®ç»“æ„é˜¶æ®µ
        project_structure_stage = next(
            (stage for stage in config_stages if stage['name'] == 'project_structure'),
            {
                "name": "project_structure",
                "description": "åˆ†æéœ€æ±‚å¹¶è§„åˆ’é¡¹ç›®ç»“æ„",
                "max_tokens": 300,
                "temperature": 0.1
            }
        )
        stages.append({
            "name": project_structure_stage["name"],
            "description": project_structure_stage["description"],
            "max_tokens": project_structure_stage.get("max_tokens", 300),
            "temperature": project_structure_stage.get("temperature", 0.1),
            "depends_on": [],
            "output_patterns": ["project_structure.json"]
        })

        # æ·»åŠ ä¸»ç¨‹åºé˜¶æ®µ
        main_program_stage = next(
            (stage for stage in config_stages if stage['name'] == 'main_program'),
            {
                "name": "main_program",
                "description": "ç”Ÿæˆä¸»ç¨‹åºæ–‡ä»¶",
                "max_tokens": 800,
                "temperature": 0.2
            }
        )
        stages.append({
            "name": main_program_stage["name"],
            "description": main_program_stage["description"],
            "max_tokens": main_program_stage.get("max_tokens", 800),
            "temperature": main_program_stage.get("temperature", 0.2),
            "depends_on": ["project_structure"],
            "output_patterns": ["main.txt"]
        })
        
        # æ ¹æ®æ£€æµ‹åˆ°çš„ç»„ä»¶æ·»åŠ ç›¸åº”é˜¶æ®µ
        component_stage_mapping = {
            "platforms": {
                "config_name": "platforms",
                "default": {
                    "name": "platforms",
                    "description": "ç”Ÿæˆå¹³å°å®šä¹‰æ–‡ä»¶",
                    "max_tokens": 1200,
                    "temperature": 0.15
                }
            },
            "scenarios": {
                "config_name": "scenarios",
                "default": {
                    "name": "scenarios",
                    "description": "ç”Ÿæˆåœºæ™¯æ–‡ä»¶",
                    "max_tokens": 1000,
                    "temperature": 0.15
                }
            },
            "processors": {
                "config_name": "processors",
                "default": {
                    "name": "processors",
                    "description": "ç”Ÿæˆå¤„ç†å™¨æ–‡ä»¶",
                    "max_tokens": 900,
                    "temperature": 0.15
                }
            },
            "sensors": {
                "config_name": "sensors",
                "default": {
                    "name": "sensors",
                    "description": "ç”Ÿæˆä¼ æ„Ÿå™¨æ–‡ä»¶",
                    "max_tokens": 700,
                    "temperature": 0.15
                }
            },
            "weapons": {
                "config_name": "weapons",
                "default": {
                    "name": "weapons",
                    "description": "ç”Ÿæˆæ­¦å™¨æ–‡ä»¶",
                    "max_tokens": 700,
                    "temperature": 0.15
                }
            },
            "signatures": {
                "config_name": None,  # é…ç½®ä¸­å¯èƒ½æ²¡æœ‰signaturesé˜¶æ®µ
                "default": {
                    "name": "signatures",
                    "description": "ç”Ÿæˆç‰¹å¾ä¿¡å·æ–‡ä»¶",
                    "max_tokens": 600,
                    "temperature": 0.1
                }
            }
        }

        # æ·»åŠ æ£€æµ‹åˆ°çš„ç»„ä»¶çš„é˜¶æ®µ
        for component, has_component in components.items():
            if has_component and component in component_stage_mapping:
                mapping = component_stage_mapping[component]
                
                # ä»é…ç½®è·å–é˜¶æ®µå‚æ•°æˆ–ä½¿ç”¨é»˜è®¤å€¼
                if mapping["config_name"]:
                    stage_config = next(
                        (stage for stage in config_stages if stage['name'] == mapping["config_name"]),
                        mapping["default"]
                    )
                else:
                    stage_config = mapping["default"]
                
                # è®¾ç½®ä¾èµ–å…³ç³»
                depends_on = ["project_structure"]
                if component == "scenarios":
                    depends_on = ["project_structure", "platforms"]
                elif component in ["processors", "sensors", "weapons"]:
                    depends_on = ["project_structure", "platforms"]
                
                # åˆ›å»ºé˜¶æ®µå¯¹è±¡
                stage = {
                    "name": stage_config["name"],
                    "description": stage_config["description"],
                    "max_tokens": stage_config.get("max_tokens", mapping["default"]["max_tokens"]),
                    "temperature": stage_config.get("temperature", mapping["default"]["temperature"]),
                    "depends_on": depends_on,
                    "output_patterns": [f"{stage_config['name']}/*.txt"]
                }
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåé˜¶æ®µ
                if not any(s["name"] == stage["name"] for s in stages):
                    stages.append(stage)
            
        return stages

class MultiStageGenerator:
    """å¤šé˜¶æ®µç”Ÿæˆå™¨"""
    
    def __init__(self, chat_system, config):
        self.chat_system = chat_system
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.project_analyzer = AFSimProjectStructure()
        
        # é¡¹ç›®çŠ¶æ€
        self.current_project = None
        self.generated_files = []
        self.current_stage = None
        self.project_context = {}
        self.stage_results = {}

    def _execute_stage(self, stage_info: Dict, query: str, output_dir: str) -> Dict:
        """æ‰§è¡Œå•ä¸ªç”Ÿæˆé˜¶æ®µ"""
        stage_name = stage_info["name"]
        stage_max_tokens = stage_info.get("max_tokens", 1024)
        stage_temperature = stage_info.get("temperature", 0.3)
        
        try:
            print(f"\nğŸ”§ å¼€å§‹æ‰§è¡Œé˜¶æ®µ: {stage_name}")
            print(f"   é˜¶æ®µæè¿°: {stage_info.get('description', '')}")
            print(f"   ç”Ÿæˆå‚æ•°: max_tokens={stage_max_tokens}, temperature={stage_temperature}")
            
            # æ„å»ºé˜¶æ®µç‰¹å®šçš„æç¤ºè¯
            prompt = self._build_stage_prompt(stage_info, query)
            
            print(f"ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            print(f"ğŸ“ æç¤ºè¯å‰200å­—ç¬¦:\n{prompt[:200]}...")
            
            # ç”Ÿæˆå†…å®¹
            start_gen_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç”Ÿæˆå‚æ•°çš„æ–¹æ³•
            if hasattr(self.chat_system, 'generate_enhanced_response_with_params'):
                print("   ä½¿ç”¨å¸¦å‚æ•°çš„ç”Ÿæˆæ–¹æ³•...")
                result = self.chat_system.generate_enhanced_response_with_params(
                    prompt, 
                    max_tokens=stage_max_tokens,
                    temperature=stage_temperature
                )
            elif hasattr(self.chat_system, 'generate_enhanced_response'):
                print("   ä½¿ç”¨å¢å¼ºå“åº”ç”Ÿæˆæ–¹æ³•...")
                result = self.chat_system.generate_enhanced_response(prompt)
            else:
                print("   ä½¿ç”¨é»˜è®¤ç”Ÿæˆæ–¹æ³•...")
                # å°è¯•ç›´æ¥è°ƒç”¨
                result = self.chat_system(prompt)
            
            gen_duration = time.time() - start_gen_time
            print(f"âœ… ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {gen_duration:.2f}ç§’")
            
            if not result or "result" not in result:
                error_msg = "ç”Ÿæˆç»“æœä¸ºç©º"
                print(f"âŒ {error_msg}")
                return {
                    "success": False,
                    "error": error_msg
                }
            
            # è§£æç”Ÿæˆçš„å†…å®¹
            generated_content = result["result"]
            
            print(f"ğŸ“ é˜¶æ®µ {stage_name} ç”Ÿæˆå†…å®¹é•¿åº¦: {len(generated_content)} å­—ç¬¦")
            print(f"ğŸ“ ç”Ÿæˆå†…å®¹å‰300å­—ç¬¦:\n{generated_content[:300]}...")
            
            # æå–æ–‡ä»¶å†…å®¹
            extract_start = time.time()
            files = self._extract_files_from_content(generated_content, stage_info, output_dir)
            extract_duration = time.time() - extract_start
            
            print(f"ğŸ“„ é˜¶æ®µ {stage_name} æå–åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œè€—æ—¶: {extract_duration:.2f}ç§’")
            
            # ä¿å­˜æ–‡ä»¶
            save_start = time.time()
            output_files = self._save_generated_files(files, output_dir)
            save_duration = time.time() - save_start
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            context = self._extract_context_from_content(generated_content)
            
            print(f"ğŸ’¾ ä¿å­˜æ–‡ä»¶å®Œæˆï¼Œè€—æ—¶: {save_duration:.2f}ç§’")
            
            return {
                "success": True,
                "output_files": output_files,
                "context": context,
                "raw_content": generated_content[:200] + "..." if len(generated_content) > 200 else generated_content,
                "stage_name": stage_name,
                "generation_params": {
                    "max_tokens": stage_max_tokens,
                    "temperature": stage_temperature
                }
            }
            
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œé˜¶æ®µ {stage_name} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e)
            }
        
    def _build_stage_query(self, stage_info: Dict, query: str) -> str:
        """æ„å»ºé˜¶æ®µç‰¹å®šçš„æŸ¥è¯¢"""
        stage_name = stage_info["name"]
        
        # é˜¶æ®µç‰¹å®šçš„æŸ¥è¯¢å¢å¼º
        stage_queries = {
            "project_structure": f"åˆ†æä»¥ä¸‹AFSIMé¡¹ç›®éœ€æ±‚å¹¶ç”Ÿæˆé¡¹ç›®ç»“æ„è§„åˆ’:\n{query}",
            "main_program": f"æ ¹æ®é¡¹ç›®éœ€æ±‚ç”Ÿæˆä¸»ç¨‹åºæ–‡ä»¶ï¼Œéœ€æ±‚:\n{query}",
            "platforms": f"ç”Ÿæˆå¹³å°å®šä¹‰ï¼ŒåŸºäºé¡¹ç›®éœ€æ±‚:\n{query}\nå·²ç¡®å®šå¹³å°: {self.project_context.get('platforms', [])}",
            "scenarios": f"ç”Ÿæˆåœºæ™¯æ–‡ä»¶ï¼ŒåŸºäºé¡¹ç›®éœ€æ±‚:\n{query}\nå¯ç”¨å¹³å°: {self.project_context.get('platforms', [])}",
            "processors": f"ç”Ÿæˆå¤„ç†å™¨æ–‡ä»¶ï¼ŒåŸºäºé¡¹ç›®éœ€æ±‚:\n{query}\nå¹³å°ä¸Šä¸‹æ–‡: {self.project_context.get('platforms', [])}",
            "sensors": f"ç”Ÿæˆä¼ æ„Ÿå™¨æ–‡ä»¶ï¼ŒåŸºäºé¡¹ç›®éœ€æ±‚:\n{query}\nå¹³å°ä¸Šä¸‹æ–‡: {self.project_context.get('platforms', [])}",
            "weapons": f"ç”Ÿæˆæ­¦å™¨æ–‡ä»¶ï¼ŒåŸºäºé¡¹ç›®éœ€æ±‚:\n{query}\nå¹³å°ä¸Šä¸‹æ–‡: {self.project_context.get('platforms', [])}",
            "signatures": f"ç”Ÿæˆç‰¹å¾ä¿¡å·æ–‡ä»¶ï¼ŒåŸºäºé¡¹ç›®éœ€æ±‚:\n{query}\nå¹³å°ç±»å‹: {self.project_context.get('platforms', [])}"
        }
        
        return stage_queries.get(stage_name, f"ç”Ÿæˆ{stage_info['description']}ï¼Œéœ€æ±‚:\n{query}")
        
    def generate_project(self, query: str, output_dir: str = None) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„AFSIMé¡¹ç›®"""
        try:
            # 1. åˆ†æéœ€æ±‚
            self.logger.info("åˆ†æé¡¹ç›®éœ€æ±‚...")
            print("ğŸ” åˆ†æé¡¹ç›®éœ€æ±‚...")
            project_analysis = self.project_analyzer.analyze_requirements(query)
            
            print(f"âœ… éœ€æ±‚åˆ†æå®Œæˆ:")
            print(f"   æ£€æµ‹åˆ°ç»„ä»¶: {project_analysis['components']}")
            print(f"   ç”Ÿæˆé˜¶æ®µ: {len(project_analysis['stages'])} ä¸ª")
            
            # 2. å‡†å¤‡è¾“å‡ºç›®å½•
            if not output_dir:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                output_dir = os.path.join(
                    self.config.get('generation.output.base_dir', 'generated_projects'),
                    f"afsim_project_{timestamp}"
                )
            
            os.makedirs(output_dir, exist_ok=True)
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
            
            # 3. ä¿å­˜é¡¹ç›®åˆ†æ
            self.current_project = {
                "analysis": project_analysis,
                "output_dir": output_dir,
                "query": query,
                "start_time": time.time(),
                "stages": {}
            }
            
            # åˆ›å»ºé¡¹ç›®ç»“æ„
            self._create_project_structure(output_dir, project_analysis["structure"])
            
            # 4. æŒ‰é˜¶æ®µç”Ÿæˆ
            stages = project_analysis["stages"]
            total_stages = len(stages)
            
            print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œ {total_stages} ä¸ªç”Ÿæˆé˜¶æ®µ...")
            
            for idx, stage_info in enumerate(stages, 1):
                stage_name = stage_info["name"]
                stage_desc = stage_info["description"]
                stage_max_tokens = stage_info.get("max_tokens", 1024)
                stage_temperature = stage_info.get("temperature", 0.3)
                
                self.current_stage = stage_name
                print(f"\n{'='*60}")
                print(f"ğŸ“‹ é˜¶æ®µ {idx}/{total_stages}: {stage_name}")
                print(f"   æè¿°: {stage_desc}")
                print(f"   å‚æ•°: max_tokens={stage_max_tokens}, temperature={stage_temperature}")
                
                # æ£€æŸ¥ä¾èµ–
                if not self._check_stage_dependencies(stage_info):
                    self.logger.warning(f"é˜¶æ®µ {stage_name} çš„ä¾èµ–æœªæ»¡è¶³ï¼Œè·³è¿‡")
                    print(f"âš ï¸  è·³è¿‡é˜¶æ®µ {stage_name}ï¼ˆä¾èµ–æœªæ»¡è¶³ï¼‰")
                    continue
                
                # æ‰§è¡Œé˜¶æ®µç”Ÿæˆ
                stage_start = time.time()
                result = self._execute_stage(stage_info, query, output_dir)
                stage_duration = time.time() - stage_start
                
                # è®°å½•ç»“æœ
                self.current_project["stages"][stage_name] = {
                    "status": "success" if result["success"] else "failed",
                    "output_files": result.get("output_files", []),
                    "error": result.get("error"),
                    "duration": stage_duration,
                    "max_tokens": stage_max_tokens,
                    "temperature": stage_temperature
                }
                
                if result["success"]:
                    # å»é‡æ·»åŠ æ–‡ä»¶
                    for file_path in result.get("output_files", []):
                        if file_path not in self.generated_files:
                            self.generated_files.append(file_path)
                    
                    self.project_context.update(result.get("context", {}))
                    self.stage_results[stage_name] = result
                    print(f"âœ… é˜¶æ®µ {stage_name} å®Œæˆ ({stage_duration:.1f}ç§’)")
                    if result.get("output_files"):
                        print(f"   ç”Ÿæˆæ–‡ä»¶: {', '.join(result['output_files'])}")
                else:
                    self.logger.error(f"é˜¶æ®µ {stage_name} å¤±è´¥: {result.get('error')}")
                    print(f"âŒ é˜¶æ®µ {stage_name} å¤±è´¥: {result.get('error')}")
            
            # 5. ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š
            report = self._generate_project_report()
            
            self.logger.info(f"é¡¹ç›®ç”Ÿæˆå®Œæˆ: {output_dir}")
            print(f"\n{'='*60}")
            print(f"ğŸ‰ é¡¹ç›®ç”Ÿæˆå®Œæˆï¼ä½ç½®: {output_dir}")
            print(f"ğŸ“„ æ€»å…±ç”Ÿæˆ {len(self.generated_files)} ä¸ªæ–‡ä»¶")
            
            return {
                "success": True,
                "project_dir": output_dir,
                "generated_files": self.generated_files,
                "report": report,
                "project_analysis": project_analysis
            }
            
        except Exception as e:
            self.logger.error(f"é¡¹ç›®ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e)
            }
    
    def _create_project_structure(self, output_dir: str, structure: Dict):
        """åˆ›å»ºé¡¹ç›®æ–‡ä»¶å¤¹ç»“æ„"""
        self.logger.info(f"åˆ›å»ºé¡¹ç›®ç»“æ„: {output_dir}")
        
        # åˆ›å»ºæ–‡ä»¶å¤¹
        for folder in structure.get("folders", []):
            folder_path = os.path.join(output_dir, folder)
            os.makedirs(folder_path, exist_ok=True)
            self.logger.debug(f"åˆ›å»ºæ–‡ä»¶å¤¹: {folder_path}")
    
    def _check_stage_dependencies(self, stage_info: Dict) -> bool:
        """æ£€æŸ¥é˜¶æ®µä¾èµ–æ˜¯å¦æ»¡è¶³"""
        depends_on = stage_info.get("depends_on", [])
        if not depends_on:
            return True
        
        for dep in depends_on:
            if dep not in self.current_project["stages"]:
                return False
            if self.current_project["stages"][dep]["status"] != "success":
                return False
        
        return True
    
    def _build_stage_prompt(self, stage_info: Dict, query: str) -> str:
        """æ„å»ºé˜¶æ®µç‰¹å®šçš„æç¤ºè¯"""
        stage_name = stage_info["name"]
        
        # æ›´ç®€æ´æ˜ç¡®çš„é˜¶æ®µç‰¹å®šæç¤ºè¯
        stage_instructions = {
            "project_structure": f"""ç”Ÿæˆé¡¹ç›®ç»“æ„JSONã€‚

éœ€æ±‚ï¼š{query}

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "components": ["å¹³å°ç»„ä»¶åˆ—è¡¨"],
  "file_structure": {{
    "folders": ["æ–‡ä»¶å¤¹åˆ—è¡¨"],
    "files": ["æ–‡ä»¶åˆ—è¡¨"]
  }},
  "main_platform": "ä¸»è¦å¹³å°åç§°",
  "scenario_description": "åœºæ™¯æè¿°"
}}

åªè¾“å‡ºJSONï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ã€‚""",
            
            "main_program": f"""ç”ŸæˆAFSIMä¸»ç¨‹åºæ–‡ä»¶ã€‚

éœ€æ±‚ï¼š{query}

è¾“å‡ºæœ‰æ•ˆçš„AFSIMä»£ç ï¼ŒåŒ…å«ï¼š
1. includeè¯­å¥
2. å¹³å°å®šä¹‰
3. åœºæ™¯å®šä¹‰
4. è¾“å‡ºé…ç½®
5. ä»¿çœŸæ§åˆ¶

åªè¾“å‡ºAFSIMä»£ç ï¼Œä¸è¦ä»»ä½•è§£é‡Š:""",
            
            "platforms": f"""ç”ŸæˆAFSIMå¹³å°å®šä¹‰ã€‚

éœ€æ±‚ï¼š{query}

åªè¾“å‡ºAFSIMä»£ç ï¼Œä¸è¦ä»»ä½•è§£é‡Š:""",
            
            "scenarios": f"""ç”ŸæˆAFSIMåœºæ™¯æ–‡ä»¶ã€‚

éœ€æ±‚ï¼š{query}

åªè¾“å‡ºAFSIMä»£ç ï¼Œä¸è¦ä»»ä½•è§£é‡Š:ã€‚"""
        }
        
        instruction = stage_instructions.get(stage_name, f"æ ¹æ®éœ€æ±‚ç”Ÿæˆ{stage_info['description']}ã€‚\néœ€æ±‚ï¼š{query}")
        
        instruction += "\n\nåªè¾“å‡ºAFSIMä»£ç ï¼Œä¸è¦ä»»ä½•è§£é‡Š:"
        
        return instruction

    def _get_platform_requirements(self) -> str:
        """è·å–å¹³å°éœ€æ±‚æè¿°"""
        if "platforms" in self.project_context:
            platforms = self.project_context["platforms"]
            return "\n".join([f"- {p}" for p in platforms])
        return "æ ¹æ®é¡¹ç›®éœ€æ±‚ç”Ÿæˆåˆé€‚çš„å¹³å°"
    
    def _clean_generated_content(self, content: str, stage_name: str) -> str:
        """æ¸…ç†ç”Ÿæˆçš„å†…å®¹ - æ›´ä¸¥æ ¼çš„ç‰ˆæœ¬"""
        
        # ç§»é™¤æ‰€æœ‰å¼•å¯¼æ€§å’Œè§£é‡Šæ€§æ–‡å­—
        patterns_to_remove = [
            r'^ç°åœ¨ï¼Œè¯·.*$', r'^ä»¥ä¸‹æ˜¯.*$', r'^è¯¥ä»£ç .*$', r'^æ‚¨æä¾›çš„ä»£ç .*$',
            r'^ä¿®æ­£åçš„ä»£ç .*$', r'^åœ¨AFSIMä¸­.*$', r'^æ³¨æ„.*$', r'^ç¡®ä¿.*$',
            r'^ç¦æ­¢.*$', r'^ç”±äº.*$', r'^æ ¹æ®.*è¦æ±‚.*$',
            r'```[a-z]*\n', r'\n```',  # Markdownä»£ç å—
            r'^\[.*\]$',  # æ–¹æ‹¬å·å†…å®¹
            r'^è¾“å‡ºï¼š.*$', r'^ç”Ÿæˆï¼š.*$',
        ]
        
        for pattern in patterns_to_remove:
            content = re.sub(pattern, '', content, flags=re.MULTILINE | re.IGNORECASE)
        
        # ç§»é™¤é‡å¤çš„ä»£ç å—
        lines = content.split('\n')
        seen_lines = set()
        unique_lines = []
        
        for line in lines:
            line_stripped = line.strip()
            if not line_stripped:
                continue
                
            # è·³è¿‡é‡å¤çš„è¡Œï¼ˆå¯¹äºå¹³å°å®šä¹‰ç‰¹åˆ«é‡è¦ï¼‰
            if line_stripped in seen_lines:
                continue
                
            seen_lines.add(line_stripped)
            unique_lines.append(line)
        
        content = '\n'.join(unique_lines)
        
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        content = re.sub(r'\n\s*\n+', '\n\n', content)
        
        return content.strip()
    
    def _extract_files_from_content(self, content: str, stage_info: Dict, output_dir: str) -> List[Dict]:
        """ä»ç”Ÿæˆçš„å†…å®¹ä¸­æå–æ–‡ä»¶"""
        files = []
        stage_name = stage_info["name"]
        
        print(f"ğŸ” æå–é˜¶æ®µ {stage_name} çš„å†…å®¹...")
        
        if stage_name == "project_structure":
            # ç›´æ¥æŸ¥æ‰¾å¹¶æå– JSON
            import re
            
            print(f"   æŸ¥æ‰¾JSONå†…å®¹...")
            
            # å°è¯•ç›´æ¥æå–å¤§æ‹¬å·ä¸­çš„å†…å®¹
            json_pattern = r'(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})'
            matches = re.findall(json_pattern, content, re.DOTALL)
            
            if matches:
                print(f"   æ‰¾åˆ° {len(matches)} ä¸ªå¯èƒ½çš„JSONå—")
                
                for i, json_str in enumerate(matches):
                    try:
                        json_data = json.loads(json_str)
                        print(f"   JSONå— {i+1} è§£ææˆåŠŸ")
                        
                        # éªŒè¯åŸºæœ¬ç»“æ„
                        if isinstance(json_data, dict):
                            # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
                            if "components" not in json_data:
                                json_data["components"] = []
                            if "file_structure" not in json_data:
                                json_data["file_structure"] = {"folders": [], "files": []}
                            if "main_platform" not in json_data:
                                json_data["main_platform"] = ""
                            if "scenario_description" not in json_data:
                                json_data["scenario_description"] = ""
                            
                            files.append({
                                "path": "project_structure.json",
                                "content": json.dumps(json_data, indent=2, ensure_ascii=False)
                            })
                            
                            # æ›´æ–°ä¸Šä¸‹æ–‡
                            self.project_context.update(json_data)
                            print(f"   âœ… æå–åˆ°æœ‰æ•ˆJSON")
                            break  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆJSONå°±åœæ­¢
                            
                    except json.JSONDecodeError as e:
                        print(f"   JSONå— {i+1} è§£æå¤±è´¥: {e}")
                        continue
                
        elif stage_name == "main_program":
            # æå– main.txt å†…å®¹
            main_content = self._extract_main_program(content)
            if main_content:
                files.append({
                    "path": "main.txt",
                    "content": main_content
                })
                print(f"   âœ… æå–åˆ° main.txt å†…å®¹")
            else:
                # å¦‚æœæ²¡æå–åˆ°å†…å®¹ï¼Œåˆ›å»ºé»˜è®¤çš„main.txt
                print(f"   âš ï¸ æœªæå–åˆ°æœ‰æ•ˆå†…å®¹ï¼Œåˆ›å»ºé»˜è®¤main.txt")
                
                default_main = f"""# AFSIM ä¸»ç¨‹åºæ–‡ä»¶
# åŸºäºéœ€æ±‚ç”Ÿæˆ: {self.current_project.get('query', '')[:100]}

include_once base_types/platforms/tank_type_a.txt

platform_type Default_Platform WSF_PLATFORM
icon default
mover WSF_GROUND_MOVER

scenario default_scenario
description "é»˜è®¤åœºæ™¯"
duration 600.0 sec

output_config
enable_output true
output_frequency 10 Hz

simulation_control
max_time 60 s
time_step 0.1 s
log true"""
                
                files.append({
                    "path": "main.txt",
                    "content": default_main
                })
                
        else:
            # å¯¹äºå…¶ä»–é˜¶æ®µï¼Œä½¿ç”¨æ™ºèƒ½æ–‡ä»¶åˆ†å‰²
            extracted_files = self._extract_multiple_files_smart(content, stage_name)
            files.extend(extracted_files)
            print(f"   ğŸ“„ æå–åˆ° {len(extracted_files)} ä¸ªæ–‡ä»¶")
        
        return files
    
    def _extract_main_program(self, content: str) -> str:
        """ä¸“é—¨æå–main.txtå†…å®¹"""
        # æŸ¥æ‰¾AFSIMä»£ç çš„å¼€å§‹
        patterns = [
            r'(platform_type[\s\S]*?simulation_control[\s\S]*?log true)',
            r'(include[\s\S]*?simulation_control[\s\S]*?log true)',
            r'(platform_type[\s\S]*?scenario[\s\S]*?end_scenario)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if match:
                return match.group(1)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´ç»“æ„ï¼Œè¿”å›æ¸…ç†åçš„å†…å®¹
        lines = []
        code_started = False
        
        for line in content.split('\n'):
            line = line.strip()
            if not line:
                continue
                
            # æ£€æµ‹ä»£ç å¼€å§‹
            if any(keyword in line.lower() for keyword in ['platform_type', 'include', 'scenario']):
                code_started = True
                
            if code_started and 'ç¦æ­¢' not in line and 'æ³¨æ„' not in line:
                lines.append(line)
        
        return '\n'.join(lines) if lines else content[:500]
    
    def _extract_multiple_files_smart(self, content: str, folder_name: str) -> List[Dict]:
        """æ™ºèƒ½æå–å¤šä¸ªæ–‡ä»¶"""
        files = []
        
        # å¤šç§æ–‡ä»¶åˆ†éš”æ¨¡å¼
        patterns = [
            (r'=== (.+?\.txt) ===\n(.*?)(?=\n=== |\Z)', re.DOTALL),  # === æ–‡ä»¶å.txt ===
            (r'// File: (.+?\.txt)\n(.*?)(?=\n// File: |\Z)', re.DOTALL),  # // File: æ–‡ä»¶å.txt
            (r'# File: (.+?\.txt)\n(.*?)(?=\n# File: |\Z)', re.DOTALL),  # # File: æ–‡ä»¶å.txt
            (r'æ–‡ä»¶ï¼š(.+?\.txt)\n(.*?)(?=\næ–‡ä»¶ï¼š|\Z)', re.DOTALL),  # æ–‡ä»¶ï¼šæ–‡ä»¶å.txt
            (r'(\w+)_platform\.txt:\n(.*?)(?=\n\w+_platform\.txt:|\Z)', re.DOTALL),  # å¹³å°å_platform.txt:
        ]
        
        for pattern, flags in patterns:
            matches = re.findall(pattern, content, flags)
            if matches:
                for filename, file_content in matches:
                    # æ¸…ç†æ–‡ä»¶å
                    filename = filename.strip()
                    if not filename.endswith('.txt'):
                        filename += '.txt'
                    
                    # æ¸…ç†æ–‡ä»¶å†…å®¹
                    file_content = file_content.strip()
                    
                    files.append({
                        "path": f"{folder_name}/{filename}",
                        "content": file_content
                    })
                break
        
        # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„åˆ†å‰²ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        if not files:
            files = self._extract_files_by_platform_pattern(content, folder_name)
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤æ–‡ä»¶
        if not files and content.strip():
            default_name = f"{folder_name}_main.txt"
            files.append({
                "path": f"{folder_name}/{default_name}",
                "content": content.strip()
            })
        
        return files
    
    def _extract_files_by_platform_pattern(self, content: str, folder_name: str) -> List[Dict]:
        """æ ¹æ®å¹³å°æ¨¡å¼æå–æ–‡ä»¶"""
        files = []
        
        # æŸ¥æ‰¾å¹³å°å®šä¹‰
        platform_patterns = [
            r'platform_type\s+(\w+)',
            r'class\s+(\w+)\s*\{',
            r'(\w+)_platform\s*\{'
        ]
        
        all_platforms = []
        for pattern in platform_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            all_platforms.extend(matches)
        
        # ä¸ºæ¯ä¸ªå¹³å°æå–ç›¸å…³å†…å®¹
        for platform in set(all_platforms):
            # æŸ¥æ‰¾è¯¥å¹³å°çš„ç›¸å…³å†…å®¹
            platform_content = self._extract_platform_content(content, platform)
            if platform_content:
                filename = f"{platform}.txt"
                files.append({
                    "path": f"{folder_name}/{filename}",
                    "content": platform_content
                })
        
        return files
    
    def _extract_platform_content(self, content: str, platform: str) -> str:
        """æå–ç‰¹å®šå¹³å°çš„å†…å®¹"""
        # æŸ¥æ‰¾ä»¥å¹³å°åå¼€å§‹çš„éƒ¨åˆ†
        patterns = [
            fr'platform_type\s+{platform}.*?\n}}(?=\n|$)' if '}' in content else fr'platform_type\s+{platform}.*?(?=\nplatform_type|\Z)',
            fr'class\s+{platform}.*?\n}}(?=\n|$)' if '}' in content else fr'class\s+{platform}.*?(?=\nclass|\Z)',
            fr'{platform}_platform.*?\n}}(?=\n|$)' if '}' in content else fr'{platform}_platform.*?(?=\n\w+_platform|\Z)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if match:
                return match.group().strip()
        
        return ""
    
    def _save_generated_files(self, files: List[Dict], output_dir: str) -> List[str]:
        """ä¿å­˜ç”Ÿæˆçš„æ–‡ä»¶"""
        saved_files = []
        
        for file_info in files:
            try:
                file_path = os.path.join(output_dir, file_info["path"])
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                
                # ä¿å­˜æ–‡ä»¶
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(file_info["content"])
                
                saved_files.append(file_info["path"])
                self.logger.info(f"âœ… ä¿å­˜æ–‡ä»¶: {file_info['path']} ({len(file_info['content'])} å­—ç¬¦)")
                
                # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
                print(f"   âœ“ ä¿å­˜: {file_info['path']}")
                
            except Exception as e:
                error_msg = f"ä¿å­˜æ–‡ä»¶å¤±è´¥ {file_info['path']}: {e}"
                self.logger.error(error_msg)
                print(f"   âœ— å¤±è´¥: {error_msg}")
        
        return saved_files
    
    def _extract_context_from_content(self, content: str) -> Dict:
        """ä»å†…å®¹ä¸­æå–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context = {}
        
        # æå–å¹³å°åç§°
        platform_matches = re.findall(r'platform_type\s+(\w+)', content, re.IGNORECASE)
        if platform_matches:
            context["platforms"] = list(set(platform_matches))
        
        # æå–æ­¦å™¨åç§°
        weapon_matches = re.findall(r'weapon_type\s+(\w+)', content, re.IGNORECASE)
        if weapon_matches:
            context["weapons"] = list(set(weapon_matches))
        
        # æå–ä¼ æ„Ÿå™¨åç§°
        sensor_matches = re.findall(r'sensor_type\s+(\w+)', content, re.IGNORECASE)
        if sensor_matches:
            context["sensors"] = list(set(sensor_matches))
        
        # æå–åœºæ™¯åç§°
        scenario_matches = re.findall(r'scenario\s+(\w+)', content, re.IGNORECASE)
        if scenario_matches:
            context["scenarios"] = list(set(scenario_matches))
        
        return context
    
    def _generate_project_report(self) -> Dict:
        """ç”Ÿæˆé¡¹ç›®æŠ¥å‘Š"""
        if not self.current_project:
            return {}
        
        total_duration = time.time() - self.current_project["start_time"]
        
        return {
            "project_info": {
                "output_dir": self.current_project["output_dir"],
                "query": self.current_project["query"],
                "total_duration": total_duration,
                "generated_files_count": len(self.generated_files)
            },
            "analysis": self.current_project["analysis"],
            "stage_results": self.current_project["stages"],
            "file_list": self.generated_files,
            "summary": {
                "total_stages": len(self.current_project["stages"]),
                "successful_stages": sum(1 for s in self.current_project["stages"].values() 
                                       if s["status"] == "success"),
                "total_files": len(self.generated_files),
                "avg_stage_duration": total_duration / max(len(self.current_project["stages"]), 1),
                "stage_params": {
                    stage_name: {
                        "max_tokens": stage_info.get("max_tokens"),
                        "temperature": stage_info.get("temperature")
                    }
                    for stage_name, stage_info in self.current_project["stages"].items()
                }
            }
        }


class MultiStageChatSystem:
    """æ”¯æŒå¤šé˜¶æ®µç”Ÿæˆçš„èŠå¤©ç³»ç»Ÿ"""
    
    def __init__(self, project_root: str, model_path: str = None):
        from rag_enhanced import EnhancedRAGChatSystem
        from utils import setup_logging, ConfigManager
        
        # è®¾ç½®æ—¥å¿—
        setup_logging()
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–åŸºç¡€RAGç³»ç»Ÿ
        self.chat_system = EnhancedRAGChatSystem(
            project_root=project_root,
            model_path=model_path
        )
        
        # åŠ è½½é…ç½®
        self.config = ConfigManager()
        
        # åˆå§‹åŒ–å¤šé˜¶æ®µç”Ÿæˆå™¨
        self.project_analyzer = AFSimProjectStructure()
        self.multi_stage_generator = MultiStageGenerator(self.chat_system, self.config)
    
    def generate_complete_project(self, query: str, output_dir: str = None) -> Dict:
        """ç”Ÿæˆå®Œæ•´çš„AFSIMé¡¹ç›®"""
        self.logger.info(f"å¼€å§‹ç”Ÿæˆå®Œæ•´é¡¹ç›®: {query[:100]}...")
        
        # ä½¿ç”¨å¤šé˜¶æ®µç”Ÿæˆå™¨
        result = self.multi_stage_generator.generate_project(query, output_dir)
        
        # è®°å½•åˆ°å¯¹è¯å†å²
        self.chat_system.conversation_history.append({
            'query': query,
            'type': 'project_generation',
            'result': result,
            'timestamp': time.time()
        })
        
        return result
    
    def get_project_info(self):
        """è·å–é¡¹ç›®ä¿¡æ¯"""
        return self.chat_system.get_project_info()
    
    def get_vector_db_info(self):
        """è·å–å‘é‡æ•°æ®åº“ä¿¡æ¯"""
        return self.chat_system.get_vector_db_info()